{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Brainiac_Numpy_Extration_for_25_Periods.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DariusTheGeek/Radiant-Earth-Spot-the-Crop-Challenge/blob/main/Brainiac_Numpy_Extration_for_25_Periods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vemh8H3vZ9VO"
      },
      "source": [
        "# Install libraries\n",
        "!pip -qq install rasterio tifffile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mKYb4JmMBEZ"
      },
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import gc\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm_notebook\n",
        "import h5py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import rasterio\n",
        "import tifffile as tiff\n",
        "\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAFPT_D_ovYr"
      },
      "source": [
        "# Download data with a frequency of 10 days\n",
        "def date_finder(start_date):\n",
        "  season_dates = []\n",
        "  m = str(start_date)[:10]\n",
        "  s = str(start_date)[:10]\n",
        "  for i in range(24):\n",
        "    date = datetime.strptime(s, \"%Y-%m-%d\")\n",
        "    s = str(date + timedelta(days = 10))[:10]\n",
        "    season_dates.append(datetime.strptime(s, \"%Y-%m-%d\"))\n",
        "  seasons_dates = [datetime.strptime(m, \"%Y-%m-%d\")] + season_dates\n",
        "  seasons_dates = [np.datetime64(x) for x in seasons_dates]\n",
        "  return list(seasons_dates)\n",
        "\n",
        "# If day not in a frequency of 10 days, find the nearest date\n",
        "def nearest(items, pivot):\n",
        "    return min(items, key=lambda x: abs(x - pivot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiS1dNGpRHBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0ef8c1b-1d0d-4fe7-8998-e8e3f1d9118f"
      },
      "source": [
        "%%time\n",
        "# Unpack data saved in gdrive to colab\n",
        "shutil.unpack_archive('/content/drive/MyDrive/CompeData/Radiant/Radiant_Data.zip', '/content/radiant')\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13min 43s, sys: 4min 22s, total: 18min 5s\n",
            "Wall time: 27min 23s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0_JwAo0bMdV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "0b21aed2-dc7b-414c-fcd6-8340d6ca3f8c"
      },
      "source": [
        "# Load files\n",
        "train = pd.concat([pd.read_csv(f'/content/radiant/train{i}.csv', parse_dates=['datetime']) for i in range(1, 5)]).reset_index(drop = True)\n",
        "test = pd.concat([pd.read_csv(f'/content/radiant/test{i}.csv', parse_dates=['datetime']) for i in range(1, 5)]).reset_index(drop = True)\n",
        "train.file_path = train.file_path.apply(lambda x: '/'.join(['/content', 'radiant'] + x.split('/')[2:]))\n",
        "test.file_path = test.file_path.apply(lambda x: '/'.join(['/content', 'radiant'] + x.split('/')[2:]))\n",
        "train.datetime, test.datetime = pd.to_datetime(train.datetime.dt.date), pd.to_datetime(test.datetime.dt.date)\n",
        "train['month'], test['month'] = train.datetime.dt.month, test.datetime.dt.month\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tile_id</th>\n",
              "      <th>datetime</th>\n",
              "      <th>satellite_platform</th>\n",
              "      <th>asset</th>\n",
              "      <th>file_path</th>\n",
              "      <th>month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2587</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>documentation</td>\n",
              "      <td>/content/radiant/ref_south_africa_crops_competition_v1_train_labels/_common/documentation.pdf</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2587</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>field_ids</td>\n",
              "      <td>/content/radiant/ref_south_africa_crops_competition_v1_train_labels/ref_south_africa_crops_competition_v1_train_labels_2587/field_ids.tif</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2587</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>field_info_train</td>\n",
              "      <td>/content/radiant/ref_south_africa_crops_competition_v1_train_labels/_common/field_info_train.csv</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2587</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>labels</td>\n",
              "      <td>/content/radiant/ref_south_africa_crops_competition_v1_train_labels/ref_south_africa_crops_competition_v1_train_labels_2587/labels.tif</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2587</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>raster_values</td>\n",
              "      <td>/content/radiant/ref_south_africa_crops_competition_v1_train_labels/_common/raster_values.json</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tile_id  ... month\n",
              "0     2587  ...   NaN\n",
              "1     2587  ...   NaN\n",
              "2     2587  ...   NaN\n",
              "3     2587  ...   NaN\n",
              "4     2587  ...   NaN\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph__jwFtDmR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c45381-5b4f-47de-f2ff-4d264fb2eb7d"
      },
      "source": [
        "# Unique months\n",
        "train.month.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idcCxN2tAbQz"
      },
      "source": [
        "# Bands\n",
        "bands = ['B01','B02','B03','B04','B05','B06','B07','B08','B8A','B09','B11','B12','CLM']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJhxiJcXAbNN"
      },
      "source": [
        "# Function to load tile and extract fields data into a numpy array and convert the same to a dataframe\n",
        "# Train\n",
        "def process_tile_train(tile):\n",
        "  tile_df = train[(train.tile_id == tile)].reset_index(drop = True)\n",
        "\n",
        "  y = np.expand_dims(rasterio.open(tile_df[tile_df.asset == 'labels'].file_path.values[0]).read(1).flatten(), axis = 1)\n",
        "  fields = np.expand_dims(rasterio.open(tile_df[tile_df.asset == 'field_ids'].file_path.values[0]).read(1).flatten(), axis = 1)\n",
        "\n",
        "  tile_df = train[(train.tile_id == tile) & (train.satellite_platform == 's2')].reset_index(drop = True)\n",
        "\n",
        "  unique_dates = list(tile_df.datetime.unique())\n",
        "  start_date = tile_df.datetime.unique()[0]\n",
        "  # Assert\n",
        "  diff = set([str(x)[:10] for x in date_finder(start_date)]) - set([str(x)[:10] for x in unique_dates])\n",
        "  if len(diff) > 0:\n",
        "    missing = list(set([str(x)[:10] for x in date_finder(start_date)]) - set(diff))\n",
        "    for d in diff:\n",
        "      missing.append(str(nearest(unique_dates, np.datetime64(d)))[:10])\n",
        "    dates = sorted([np.datetime64(x) for x in missing]) \n",
        "  else:\n",
        "    dates = date_finder(start_date)\n",
        "\n",
        "  X_tile = np.empty((256 * 256, 0))\n",
        "\n",
        "  colls = []\n",
        "  for date, datec in zip(dates, range(25)):\n",
        "    for band in bands:\n",
        "      tif_file = tile_df[(tile_df.asset == band) & (tile_df.datetime == date)].file_path.values[0]\n",
        "      X_tile = np.append(X_tile, (np.expand_dims(rasterio.open(tif_file).read(1).flatten(), axis = 1)), axis = 1)\n",
        "      colls.append(str(datec) + '_' + band)\n",
        "  df = pd.DataFrame(X_tile, columns = colls)\n",
        "  df['y'], df['fields'] = y, fields\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hQOhSMPb-qI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2ab606-a1b3-440f-8df4-546cc0be0b2d"
      },
      "source": [
        "# Preprocessing the data in chunks to avoid outofmemmory error\n",
        "# Train\n",
        "tiles = train.tile_id.unique()\n",
        "chunks = [tiles[x:x+50] for x in range(0, len(tiles), 50)]\n",
        "[len(x) for x in chunks], len(chunks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50,\n",
              "  50],\n",
              " 53)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iULhCd36KrGG"
      },
      "source": [
        "# Preprocessing the tiles without storing them in memory but saving them as csvs in gdrive\n",
        "# Train\n",
        "for i in range(len(chunks)):\n",
        "  pd.DataFrame(np.vstack(Parallel(n_jobs=-1, verbose=1, backend=\"multiprocessing\")(map(delayed(process_tile_train), [x for x in chunks[i]])))).to_csv(f'/content/drive/MyDrive/CompeData/Radiant/Seasonality/train/train{i}.csv', index = False)\n",
        "  gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scZ6uxWaz0Fq"
      },
      "source": [
        "# Function to load tile and extract fields data into a numpy array and convert the same to a dataframe\n",
        "# Test\n",
        "def process_tile_test(tile):\n",
        "  tile_df = test[(test.tile_id == tile)].reset_index(drop = True)\n",
        "\n",
        "  fields = np.expand_dims(rasterio.open(tile_df[tile_df.asset == 'field_ids'].file_path.values[0]).read(1).flatten(), axis = 1)\n",
        "\n",
        "  tile_df = test[(test.tile_id == tile) & (test.satellite_platform == 's2')].reset_index(drop = True)\n",
        "\n",
        "  unique_dates = list(tile_df.datetime.unique())\n",
        "  start_date = tile_df.datetime.unique()[0]\n",
        "  # Assert\n",
        "  diff = set([str(x)[:10] for x in date_finder(start_date)]) - set([str(x)[:10] for x in unique_dates])\n",
        "  if len(diff) > 0:\n",
        "    missing = list(set([str(x)[:10] for x in date_finder(start_date)]) - set(diff))\n",
        "    for d in diff:\n",
        "      missing.append(str(nearest(unique_dates, np.datetime64(d)))[:10])\n",
        "    dates = sorted([np.datetime64(x) for x in missing]) \n",
        "  else:\n",
        "    dates = date_finder(start_date)\n",
        "\n",
        "  X_tile = np.empty((256 * 256, 0))\n",
        "\n",
        "  colls = []\n",
        "  for date, datec in zip(dates, range(25)):\n",
        "    for band in bands:\n",
        "      tif_file = tile_df[(tile_df.asset == band) & (tile_df.datetime == date)].file_path.values[0]\n",
        "      X_tile = np.append(X_tile, (np.expand_dims(rasterio.open(tif_file).read(1).flatten(), axis = 1)), axis = 1)\n",
        "      colls.append(str(datec) + '_' + band)\n",
        "  df = pd.DataFrame(X_tile, columns = colls)\n",
        "  df['fields'] = fields\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2-rj6T9z0Co"
      },
      "source": [
        "# Preprocessing the data in chunks to avoid outofmemmory error\n",
        "# Train\n",
        "tiles = test.tile_id.unique()\n",
        "chunks = [tiles[x:x+50] for x in range(0, len(tiles), 50)]\n",
        "[len(x) for x in chunks], len(chunks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifNd5fgxzz_1"
      },
      "source": [
        "# Preprocessing the tiles without storing them in memory but saving them as csvs in gdrive\n",
        "# Train\n",
        "for i in range(len(chunks)):\n",
        "  pd.DataFrame(np.vstack(Parallel(n_jobs=-1, verbose=1, backend=\"multiprocessing\")(map(delayed(process_tile_test), [x for x in chunks[i]])))).to_csv(f'/content/drive/MyDrive/CompeData/Radiant/Seasonality/test/test{i}.csv', index = False)\n",
        "  gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}